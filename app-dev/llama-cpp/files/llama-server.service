[Unit]
Description=Llama Server
Documentation=man:llama-server(1)
After=network.target
Requires=network.target

[Service]
Type=simple
User=llama
Group=llama
WorkingDirectory=/opt/llm-models
EnvironmentFile=/etc/llama-server/llama-server.env
ExecStart=/usr/bin/env llama-server \
    --n-gpu-layers ${N_GPU_LAYERS} \
    --threads ${THREADS} \
    --ctx-size ${CTX_SIZE} \
    --temp ${TEMP} \
    --top_p ${TOP_P} \
    $EXTRA_FLAGS \
    --model "${MODEL_PATH}"
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=always
RestartSec=5s
Environment=PATH=/opt/llm-models/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin

[Install]
WantedBy=multi-user.target
